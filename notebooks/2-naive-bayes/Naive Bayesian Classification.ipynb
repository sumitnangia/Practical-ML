{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You might need to install spacy and download an english model\n",
    "# !pip install spacy\n",
    "# !python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /home/hexgnu/.pyenv/versions/3.7.3/lib/python3.7/site-packages (0.0)\r\n",
      "Requirement already satisfied: scikit-learn in /home/hexgnu/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from sklearn) (0.21.2)\r\n",
      "Requirement already satisfied: scipy>=0.17.0 in /home/hexgnu/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.3.0)\r\n",
      "Requirement already satisfied: numpy>=1.11.0 in /home/hexgnu/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.16.4)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /home/hexgnu/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from scikit-learn->sklearn) (0.13.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have a bunch of emails on disk\n",
    "\n",
    "import glob\n",
    "import io\n",
    "import spacy\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import email\n",
    "import re\n",
    "\n",
    "# nlp = spacy.load('en')\n",
    "\n",
    "# corpus = Counter()\n",
    "# emails = []\n",
    "\n",
    "# with open('./data/SPAMTrain.label', 'r') as file:\n",
    "#     for i, line in enumerate(file):\n",
    "#         # You can always look at all of the files too!\n",
    "#         print('.', end='')\n",
    "        \n",
    "#         spam, eml = line.split(' ')\n",
    "#         eml = \"./data/TRAINING/{}\".format(eml.strip())\n",
    "        \n",
    "#         c = Counter()\n",
    "#         with open(eml, 'r', errors='replace') as full_message: \n",
    "#             msg = email.message_from_string(full_message.read())\n",
    "#             if not msg.is_multipart() and msg.get_content_type() == 'text/plain':\n",
    "#                 payload = str(msg.get_payload())\n",
    "#                 for t in nlp(re.sub(r'\\s+', ' ', payload)):\n",
    "#                     c[t.lemma_] += 1\n",
    "\n",
    "#         if len(c) > 0:\n",
    "#             emails.append({'SPAM_VALUE': spam, **dict(c)})\n",
    "\n",
    "# eml_df = pd.DataFrame(emails)\n",
    "\n",
    "# keys = []\n",
    "\n",
    "# for c in eml_df.columns:\n",
    "#     if eml_df[c].sum() > 10:\n",
    "#         print('.', end='')\n",
    "#         keys.append(c)\n",
    "\n",
    "# eml_df = eml_df[keys]\n",
    "\n",
    "# eml_df.to_csv('./email-training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Unnamed: 0.1', ' ', '!', '\"', '#', '$', '%', '&', ''',\n",
       "       ...\n",
       "       '~', '~$', '~/.kde', '~~~', '»', 'й', 'չ', '─', '│', '�'],\n",
       "      dtype='object', length=5062)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eml_df = pd.read_csv('./email-training.csv')\n",
    "\n",
    "eml_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         NaN\n",
       "1         NaN\n",
       "2         3.0\n",
       "3         6.0\n",
       "4         8.0\n",
       "5         1.0\n",
       "6         3.0\n",
       "7        11.0\n",
       "8        12.0\n",
       "9         1.0\n",
       "10        4.0\n",
       "11        1.0\n",
       "12        NaN\n",
       "13        9.0\n",
       "14       46.0\n",
       "15        1.0\n",
       "16        NaN\n",
       "17        4.0\n",
       "18        NaN\n",
       "19        3.0\n",
       "20        8.0\n",
       "21        4.0\n",
       "22        1.0\n",
       "23        1.0\n",
       "24        8.0\n",
       "25        7.0\n",
       "26       11.0\n",
       "27       91.0\n",
       "28        NaN\n",
       "29       20.0\n",
       "        ...  \n",
       "2911      NaN\n",
       "2912     18.0\n",
       "2913      3.0\n",
       "2914     15.0\n",
       "2915      3.0\n",
       "2916      NaN\n",
       "2917      6.0\n",
       "2918     12.0\n",
       "2919      7.0\n",
       "2920     10.0\n",
       "2921      NaN\n",
       "2922      NaN\n",
       "2923      6.0\n",
       "2924      7.0\n",
       "2925      5.0\n",
       "2926      4.0\n",
       "2927     29.0\n",
       "2928      NaN\n",
       "2929      8.0\n",
       "2930      2.0\n",
       "2931     19.0\n",
       "2932      7.0\n",
       "2933      NaN\n",
       "2934      1.0\n",
       "2935     17.0\n",
       "2936    105.0\n",
       "2937      4.0\n",
       "2938     16.0\n",
       "2939     13.0\n",
       "2940      NaN\n",
       "Name: the, Length: 2941, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eml_df['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hexgnu/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94       330\n",
      "           1       1.00      0.98      0.99      2611\n",
      "\n",
      "    accuracy                           0.99      2941\n",
      "   macro avg       0.94      0.99      0.97      2941\n",
      "weighted avg       0.99      0.99      0.99      2941\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Normal distribution bell curve: Gaussian\n",
    "# Beroulli: \n",
    "\n",
    "clf = BernoulliNB(alpha=0.0)\n",
    "\n",
    "X = eml_df[eml_df.columns[~eml_df.columns.isin(['SPAM_VALUE'])]].fillna(value=0)\n",
    "y = eml_df['SPAM_VALUE']\n",
    "\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Why is the value what it is? What would you do to fix this?\n",
    "\n",
    "print(classification_report(clf.predict(X), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SPAM_VALUE\n",
       "0     307\n",
       "1    2034\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eml_df.groupby('SPAM_VALUE').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89        59\n",
      "           1       0.99      0.98      0.99       530\n",
      "\n",
      "    accuracy                           0.98       589\n",
      "   macro avg       0.92      0.96      0.94       589\n",
      "weighted avg       0.98      0.98      0.98       589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = BernoulliNB(alpha=0.06)\n",
    "# clf = GaussianNB()\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(classification_report(clf.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 61,  35],\n",
       "       [  4, 489]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(clf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was able to get ~0.94 for precision on both Ham(1) and Spam(0). That's pretty good! The recall isn't so good actually. A 0.60 recall isn't so great, although we could probably do better on parsing the Emails themselves. Think of some reasons how this result could get better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BONUS word2vec\n",
    "\n",
    "Word2Vec is an amazing model to fit natural language to a vectorized representation. Matter of fact it's called representation learning and basically will take text and output something that we can do math on!\n",
    "\n",
    "Below I've done the heavy lifting of giving you a word2vec file to train on. Try out GaussianNB and see what happens. Is it any better or worse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."
     ]
    }
   ],
   "source": [
    "# emails = []\n",
    "# import numpy as np\n",
    "\n",
    "# with open('./data/SPAMTrain.label', 'r') as file:\n",
    "#     for i, line in enumerate(file):\n",
    "#         # You can always look at all of the files too!\n",
    "#         print('.', end='')\n",
    "        \n",
    "#         spam, eml = line.split(' ')\n",
    "#         eml = \"./data/TRAINING/{}\".format(eml.strip())\n",
    "        \n",
    "#         vector = np.zeros(0)\n",
    "#         with open(eml, 'r', errors='replace') as full_message: \n",
    "#             msg = email.message_from_string(full_message.read())\n",
    "#             if not msg.is_multipart() and msg.get_content_type() == 'text/plain':\n",
    "#                 payload = str(msg.get_payload())\n",
    "                \n",
    "#                 s = nlp(re.sub(r'\\s+', ' ', payload))\n",
    "                \n",
    "#                 vector = s.vector\n",
    "\n",
    "#         if np.sum(vector) > 0:\n",
    "#             emails.append({'SPAM_VALUE': spam, **dict(zip(range(384), vector))})\n",
    "\n",
    "# eml_df = pd.DataFrame(emails)\n",
    "\n",
    "# eml_df.to_csv('./emails-word2vec.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>SPAM_VALUE</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>374</th>\n",
       "      <th>375</th>\n",
       "      <th>376</th>\n",
       "      <th>377</th>\n",
       "      <th>378</th>\n",
       "      <th>379</th>\n",
       "      <th>380</th>\n",
       "      <th>381</th>\n",
       "      <th>382</th>\n",
       "      <th>383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.248722</td>\n",
       "      <td>1.391528</td>\n",
       "      <td>1.087005</td>\n",
       "      <td>1.136443</td>\n",
       "      <td>0.088674</td>\n",
       "      <td>1.147383</td>\n",
       "      <td>-1.577564</td>\n",
       "      <td>-0.270032</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013487</td>\n",
       "      <td>-0.028195</td>\n",
       "      <td>0.032172</td>\n",
       "      <td>0.031236</td>\n",
       "      <td>0.210149</td>\n",
       "      <td>0.154497</td>\n",
       "      <td>-0.072023</td>\n",
       "      <td>0.115364</td>\n",
       "      <td>0.265590</td>\n",
       "      <td>-0.013191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.576246</td>\n",
       "      <td>0.697309</td>\n",
       "      <td>1.015784</td>\n",
       "      <td>1.422330</td>\n",
       "      <td>0.060741</td>\n",
       "      <td>-0.074634</td>\n",
       "      <td>-0.671568</td>\n",
       "      <td>-0.578649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038255</td>\n",
       "      <td>0.004724</td>\n",
       "      <td>-0.024387</td>\n",
       "      <td>-0.000826</td>\n",
       "      <td>0.011039</td>\n",
       "      <td>0.079151</td>\n",
       "      <td>-0.082945</td>\n",
       "      <td>0.182521</td>\n",
       "      <td>-0.004091</td>\n",
       "      <td>-0.058852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.172061</td>\n",
       "      <td>0.395070</td>\n",
       "      <td>0.754064</td>\n",
       "      <td>0.677915</td>\n",
       "      <td>0.453942</td>\n",
       "      <td>-0.450965</td>\n",
       "      <td>-0.441118</td>\n",
       "      <td>-0.652330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109467</td>\n",
       "      <td>-0.023011</td>\n",
       "      <td>0.020112</td>\n",
       "      <td>-0.051621</td>\n",
       "      <td>0.087226</td>\n",
       "      <td>0.066990</td>\n",
       "      <td>-0.057918</td>\n",
       "      <td>0.115030</td>\n",
       "      <td>0.127236</td>\n",
       "      <td>0.021688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.050888</td>\n",
       "      <td>0.085505</td>\n",
       "      <td>0.706955</td>\n",
       "      <td>1.214564</td>\n",
       "      <td>0.098087</td>\n",
       "      <td>-0.053080</td>\n",
       "      <td>-0.548602</td>\n",
       "      <td>0.080831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173510</td>\n",
       "      <td>0.044773</td>\n",
       "      <td>0.093819</td>\n",
       "      <td>-0.079164</td>\n",
       "      <td>0.136898</td>\n",
       "      <td>0.110524</td>\n",
       "      <td>-0.019751</td>\n",
       "      <td>0.160244</td>\n",
       "      <td>0.141444</td>\n",
       "      <td>-0.014389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.647508</td>\n",
       "      <td>0.685397</td>\n",
       "      <td>0.534541</td>\n",
       "      <td>1.115465</td>\n",
       "      <td>0.333897</td>\n",
       "      <td>-0.481878</td>\n",
       "      <td>-1.361484</td>\n",
       "      <td>0.132314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265855</td>\n",
       "      <td>0.035184</td>\n",
       "      <td>0.228359</td>\n",
       "      <td>0.056503</td>\n",
       "      <td>0.240884</td>\n",
       "      <td>0.111331</td>\n",
       "      <td>-0.003491</td>\n",
       "      <td>0.142417</td>\n",
       "      <td>0.179619</td>\n",
       "      <td>0.119642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 386 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  SPAM_VALUE         0         1         2         3         4  \\\n",
       "0           0           0  0.248722  1.391528  1.087005  1.136443  0.088674   \n",
       "1           1           0  0.576246  0.697309  1.015784  1.422330  0.060741   \n",
       "2           2           1 -0.172061  0.395070  0.754064  0.677915  0.453942   \n",
       "3           3           1 -0.050888  0.085505  0.706955  1.214564  0.098087   \n",
       "4           4           1  0.647508  0.685397  0.534541  1.115465  0.333897   \n",
       "\n",
       "          5         6         7  ...       374       375       376       377  \\\n",
       "0  1.147383 -1.577564 -0.270032  ... -0.013487 -0.028195  0.032172  0.031236   \n",
       "1 -0.074634 -0.671568 -0.578649  ...  0.038255  0.004724 -0.024387 -0.000826   \n",
       "2 -0.450965 -0.441118 -0.652330  ...  0.109467 -0.023011  0.020112 -0.051621   \n",
       "3 -0.053080 -0.548602  0.080831  ...  0.173510  0.044773  0.093819 -0.079164   \n",
       "4 -0.481878 -1.361484  0.132314  ...  0.265855  0.035184  0.228359  0.056503   \n",
       "\n",
       "        378       379       380       381       382       383  \n",
       "0  0.210149  0.154497 -0.072023  0.115364  0.265590 -0.013191  \n",
       "1  0.011039  0.079151 -0.082945  0.182521 -0.004091 -0.058852  \n",
       "2  0.087226  0.066990 -0.057918  0.115030  0.127236  0.021688  \n",
       "3  0.136898  0.110524 -0.019751  0.160244  0.141444 -0.014389  \n",
       "4  0.240884  0.111331 -0.003491  0.142417  0.179619  0.119642  \n",
       "\n",
       "[5 rows x 386 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eml_df = pd.read_csv('./emails-word2vec.csv')\n",
    "\n",
    "eml_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.70      0.70        54\n",
      "          1       0.96      0.96      0.96       415\n",
      "\n",
      "avg / total       0.93      0.93      0.93       469\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "clf = LinearSVC(C=50)\n",
    "\n",
    "X = eml_df[eml_df.columns[~eml_df.columns.isin(['SPAM_VALUE'])]].fillna(value=0)\n",
    "y = eml_df['SPAM_VALUE']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(classification_report(clf.predict(X_test), y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
